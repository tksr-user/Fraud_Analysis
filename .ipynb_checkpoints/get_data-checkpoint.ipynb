{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c7e2cc6-9980-4823-9e78-cc3bdd805220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\aman1\\.cache\\kagglehub\\datasets\\mlg-ulb\\creditcardfraud\\versions\\3\n",
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileExistsError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     33\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mEventTime\u001b[39m\u001b[33m\"\u001b[39m] = datetime.utcnow().isoformat()\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Ensure folder exists and save\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m parquet_path = \u001b[33m\"\u001b[39m\u001b[33mdata/fraud_data.parquet\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     38\u001b[39m df.to_parquet(parquet_path, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:225\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "\u001b[31mFileExistsError\u001b[39m: [WinError 183] Cannot create a file when that file already exists: 'data'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import mlflow\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "import os\n",
    "import kagglehub\n",
    "\n",
    "# Download dataset\n",
    "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Load data\n",
    "csv_path = os.path.join(path, \"creditcard.csv\")\n",
    "df = pd.read_csv(csv_path)\n",
    "df = df.sample(n=10000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Check missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Scale Amount column\n",
    "scaler = StandardScaler()\n",
    "df['scaled_amount'] = scaler.fit_transform(df[['Amount']])\n",
    "\n",
    "# Drop original columns\n",
    "df = df.drop(['Amount', 'Time'], axis=1)\n",
    "\n",
    "# Add required columns\n",
    "df[\"TransactionID\"] = [str(uuid.uuid4()) for _ in range(len(df))]\n",
    "df[\"EventTime\"] = datetime.utcnow().isoformat()\n",
    "\n",
    "# Ensure folder exists and save\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "parquet_path = \"data/fraud_data.parquet\"\n",
    "df.to_parquet(parquet_path, index=False)\n",
    "print(\"✅ Parquet file saved:\", parquet_path)\n",
    "\n",
    "# Read Parquet file into DataFrame\n",
    "df = pd.read_parquet(parquet_path)\n",
    "print(\"✅ Parquet file loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367eb58c-6fa0-42b2-bf3a-6f2496e31dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fd34d6-cb83-43ec-b9c5-20ea2969c84e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
