{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c7e2cc6-9980-4823-9e78-cc3bdd805220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\aman1\\.cache\\kagglehub\\datasets\\mlg-ulb\\creditcardfraud\\versions\\3\n",
      "Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n",
      "✅ Parquet file saved: datas/fraud_data.parquet\n",
      "✅ Parquet file loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import mlflow\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "import os\n",
    "import kagglehub\n",
    "\n",
    "# Download dataset\n",
    "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Load data\n",
    "csv_path = os.path.join(path, \"creditcard.csv\")\n",
    "df = pd.read_csv(csv_path)\n",
    "df = df.sample(n=10000, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Check missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Scale Amount column\n",
    "scaler = StandardScaler()\n",
    "df['scaled_amount'] = scaler.fit_transform(df[['Amount']])\n",
    "\n",
    "# Drop original columns\n",
    "df = df.drop(['Amount', 'Time'], axis=1)\n",
    "\n",
    "# Add required columns\n",
    "df[\"TransactionID\"] = [str(uuid.uuid4()) for _ in range(len(df))]\n",
    "df[\"EventTime\"] = datetime.utcnow().isoformat()\n",
    "\n",
    "# Ensure folder exists and save\n",
    "os.makedirs(\"datas\", exist_ok=True)\n",
    "parquet_path = \"datas/fraud_data.parquet\"\n",
    "df.to_parquet(parquet_path, index=False)\n",
    "print(\"✅ Parquet file saved:\", parquet_path)\n",
    "\n",
    "# Read Parquet file into DataFrame\n",
    "df = pd.read_parquet(parquet_path)\n",
    "print(\"✅ Parquet file loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367eb58c-6fa0-42b2-bf3a-6f2496e31dd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fd34d6-cb83-43ec-b9c5-20ea2969c84e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
